# Efficient Training of a  Transformer Model on a Single GPU

In this project we develop a transformer model, and look into implementing the three training hacks (mixed precision, activation checkpointing and gradient accumulation) that we have discussed in a separate [repo](single-gpu-training-hacks/).
